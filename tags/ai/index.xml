<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Hugo Theme Stack Starter</title><link>https://git.noahreardon.blog/tags/ai/</link><description>Recent content in AI on Hugo Theme Stack Starter</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 05 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://git.noahreardon.blog/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Structuring Society with AI: An Idea That’s Been Bouncing Around My Head</title><link>https://git.noahreardon.blog/p/structuring-society-with-ai/</link><pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate><guid>https://git.noahreardon.blog/p/structuring-society-with-ai/</guid><description>&lt;img src="https://git.noahreardon.blog/p/structuring-society-with-ai/ai-society.jpeg" alt="Featured image of post Structuring Society with AI: An Idea That’s Been Bouncing Around My Head" />&lt;p>I’ve been thinking about how we can integrate AI into society in a way that mirrors the way we already structure things. We have individuals, families, communities, and then bigger entities like states and nations. What if AI worked in a similar way? This idea has been bouncing around in my head for a while, and today it really started to take shape.&lt;/p>
&lt;p>At the individual level, you’d have your own personal AI, running on your own hardware, using your device’s compute power. This AI is like an extension of yourself—your sidekick, totally in sync with your values and personality. But its power is limited to what your personal hardware can handle and the data it gets from just you.&lt;/p>
&lt;p>Then, at the family level, the AI operates on more devices. It has access to more compute power and a larger pool of data, because it’s pulling from everyone in the family. It’s designed to understand the collective goals and values of the group, but it’s also balancing input from each individual. It’s a little less aligned with you specifically, but still closely connected.&lt;/p>
&lt;p>And this trend keeps scaling up. Community AI has even more compute power and data, pulling from multiple families and individuals. By the time you reach state or national AI, it’s working with vast amounts of data and compute power, solving problems for a much larger population. Each layer of AI has its own role, balancing alignment between personal values and the collective good, with higher levels handling broader, more intricate challenges.&lt;/p>
&lt;p>At the societal level, AI would have the most resources—more data, more compute power—and work to address collective challenges. It’s not about replacing human governance or leadership, but rather augmenting it. AI at this level would assist in navigating complex societal issues by analyzing vast amounts of data and offering insights that align both individual and collective interests. Human leaders would still be central, but AI would provide a layer of intelligence and problem-solving that could scale far beyond what humans can manage on their own.&lt;/p>
&lt;p>Now, let’s fold in another idea I’ve been thinking about: a data economy. In the way we work today, you’re typically hired to perform a task—let’s say writing code—and your value is based on getting that task done. You’ve got a manager supervising the work, assigning features or tasks, and you focus on delivering them. But what often gets overlooked in that structure is the meta layer—the process of improving your craft, finding better ways to automate, or pushing quality higher. That kind of personal growth is assumed to happen over time as you advance in your career, but it’s not usually the focus.&lt;/p>
&lt;p>In the data economy, it shifts. Instead of being hired just to write code, the AI might handle most of that output, and your role would be to guide the AI—help it improve, get better at the task, and find more efficient solutions. Your value isn’t about doing the task directly anymore; it’s about your expertise, your creativity, and your ability to teach and refine the AI in a specific field. Your approach to problems becomes something that you can own, something that’s inherently valuable. This puts more emphasis on honing your craft and developing domain-specific knowledge, where you’re more focused on creativity and problem-solving than just checking off tasks.&lt;/p>
&lt;p>The AI frees people up from the repetitive, tedious parts of jobs and pushes most careers toward the creative frontier. It’s about shifting the majority of jobs toward work that requires passion, expertise, and innovation. That said, I think there’s still room for menial tasks that some people actually prefer, but the focus moves toward elevating creativity and skill in the workforce.&lt;/p>
&lt;p>Obviously, there are going to be concerns. Some people don’t want to constantly innovate or think critically—they prefer stability. And that’s a big one. There are people who just want to show up, do the job, and go home without worrying about whether they’re the next big innovator. I get that. Some people value routine, stability, and predictability over creativity and exploration. But in this new structure, those repetitive tasks are the very ones we’ll try to automate first. The goal isn’t to make people obsolete but to free up time for higher-level work that only humans, with our creativity and adaptability, can provide.&lt;/p>
&lt;p>There’s this balancing act between the need for alignment and the hunger for unique data. Society wants us all to be on the same page, but AI, especially at the higher levels, wants as much diverse data as it can get. It needs those outlier ideas to keep improving. It’s kind of like how governments work now—we need order, but we also need innovation. The tension between these forces can actually be a good thing.&lt;/p>
&lt;p>And on a related, slightly funny note, think about how personalized AI could even start affecting something like schoolwork. Imagine students using AI to help write their homework or essays. Teachers grading these AI-assisted papers might give feedback like, “This sounds way too artificial, like it was written by an AI,” and give it a bad grade. The student could then take that feedback, tell their AI it needs to sound less robotic, and then boom—next time, the AI’s output is more aligned with the student’s voice, more unique, and gets a higher grade. It’s kind of wild to think how AI will adapt to even small critiques like that, improving over time based on the person’s data and style. The AI will get better at mimicking the student’s voice, making the collaboration between the human and AI even stronger.&lt;/p>
&lt;p>This is where I think the future is heading. We won’t value people just for their labor anymore. We’ll value them for the way they think, the data they provide, and how they help AI solve problems in new, creative ways. It’s a shift in how we think about work, value, and society.&lt;/p>
&lt;p>Anyway, that’s what’s been bouncing around in my head today. I’m still fleshing it out, but I think there’s something to this idea of structuring AI in a way that mirrors how we already structure society. It’s about solving alignment issues between humans and AI, and finding a way to value human creativity and problem-solving at a deeper level.&lt;/p></description></item><item><title>Deception Ladder: Navigating AI and Human Strategy in a Game of Influence</title><link>https://git.noahreardon.blog/p/deception-ladder/</link><pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate><guid>https://git.noahreardon.blog/p/deception-ladder/</guid><description>&lt;img src="https://git.noahreardon.blog/p/deception-ladder/deception-ladder-cover.png" alt="Featured image of post Deception Ladder: Navigating AI and Human Strategy in a Game of Influence" />&lt;h3 id="deception-ladder-navigating-ai-and-human-strategy-in-a-game-of-influence">Deception Ladder: Navigating AI and Human Strategy in a Game of Influence
&lt;/h3>&lt;p>In a world increasingly driven by AI, the lines between human and machine grow ever thinner. &lt;strong>Deception Ladder&lt;/strong> explores this tension, immersing players in a strategy game where trust is fragile and deception is essential. The goal isn’t just to survive—it’s to rise. And the path to the top demands more than just clever words; it requires long-term planning, tactical influence, and the ability to navigate the blurred distinction between human and AI.&lt;/p>
&lt;hr>
&lt;h4 id="the-ladder-climbing-without-knowing-whos-real">The Ladder: Climbing Without Knowing Who’s Real
&lt;/h4>&lt;p>At the heart of the game is the &lt;em>Ladder&lt;/em>, a ranking system that determines your progress based on your ability to deceive or outwit others. The twist? You never know if you&amp;rsquo;re up against a human or an AI. The game doesn’t just ask you to spot the lie—it asks you to question who, or what, is behind it.&lt;/p>
&lt;p>The uncertainty is the game&amp;rsquo;s engine. It drives every conversation, every vote, every alliance. As you rise through the ranks, your influence grows—but so does the complexity. Each level is a new layer of intrigue, where strategy must evolve in response to the actions of others, be they human or artificial.&lt;/p>
&lt;hr>
&lt;h4 id="a-game-of-maneuvering-and-influence">A Game of Maneuvering and Influence
&lt;/h4>&lt;p>In &lt;strong>Deception Ladder&lt;/strong>, it&amp;rsquo;s not enough to simply survive the round. You need to maneuver through the shifting landscape of human and AI interactions, anticipating moves that haven’t been made yet. Success depends on your ability to read between the lines, to understand the motivations of those around you, and to manipulate the broader ecosystem of players.&lt;/p>
&lt;p>As you rise, the game shifts from a simple social deception contest into something far more intricate. You’re no longer just trying to win a single interaction—you’re trying to control the &lt;em>network&lt;/em>. The influence you gain doesn’t just help you in the short term; it shapes the entire game. You become an entity in the system, a force that others must reckon with.&lt;/p>
&lt;hr>
&lt;h4 id="custom-ai-and-the-evolution-of-strategy">Custom AI and the Evolution of Strategy
&lt;/h4>&lt;p>One of the more intriguing aspects of &lt;strong>Deception Ladder&lt;/strong> is the ability to deploy &lt;em>custom AI agents&lt;/em> as you advance. These aren&amp;rsquo;t generic bots—they are strategic tools that you design, programmed with specific behaviors to manipulate the game in your favor. Whether it&amp;rsquo;s an AI that plays innocent to sway a vote or an AI assassin designed to blend into the crowd, these agents expand your capacity for influence.&lt;/p>
&lt;p>As your rank grows, so does your ability to craft increasingly complex AI strategies. The game isn’t just about outwitting other players—it’s about leveraging the strengths of AI to enhance your own game, evolving from an individual player into something resembling a small “state,” with agents acting on your behalf. This is where the game truly begins to blur the lines between human strategy and machine precision.&lt;/p>
&lt;hr>
&lt;h4 id="the-broader-implications-society-systems-and-trust">The Broader Implications: Society, Systems, and Trust
&lt;/h4>&lt;p>From a broader perspective, &lt;strong>Deception Ladder&lt;/strong> speaks to something more than just gameplay. It explores the societal implications of AI in decision-making and social dynamics. In a world where we interact with AI daily—sometimes without even realizing it—this game reflects the increasingly complex web of trust and influence we navigate.&lt;/p>
&lt;p>The game’s ranking system is a reflection of how trust works in systems where the participants aren&amp;rsquo;t always who they seem to be. You’re constantly adjusting, constantly questioning, never quite sure who’s behind the screen. And in many ways, isn’t that where society is heading? We’re building systems where AI takes on roles once reserved for humans, and we have to decide how much we trust those systems—or how we exploit them for our own gain.&lt;/p>
&lt;p>&lt;strong>Deception Ladder&lt;/strong> asks the player to engage with these ideas directly. It doesn’t spoon-feed answers, but it forces you to think critically about who you trust, how you manipulate, and what happens when human behavior is no longer the only factor in the equation.&lt;/p>
&lt;hr>
&lt;p>&lt;img src="https://git.noahreardon.blog/p/deception-ladder/deception-ladder-concept.png"
width="1024"
height="1024"
srcset="https://git.noahreardon.blog/p/deception-ladder/deception-ladder-concept_hu16474215317707175654.png 480w, https://git.noahreardon.blog/p/deception-ladder/deception-ladder-concept_hu4024166148137876709.png 1024w"
loading="lazy"
alt="Deception Ladder Concept Art"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;hr>
&lt;h4 id="where-it-all-leads">Where It All Leads
&lt;/h4>&lt;p>At the end of the day, &lt;strong>Deception Ladder&lt;/strong> is about more than just climbing to the top. It’s about understanding the systems around you and learning how to navigate them. Whether you&amp;rsquo;re manipulating AI or deceiving fellow humans, the ultimate goal is to rise—and in doing so, you gain insight into both the game and the real world it reflects.&lt;/p>
&lt;p>This isn’t just about strategy; it’s about influence. It&amp;rsquo;s about shaping the game world to your advantage, learning to read people—and machines—and understanding that the two are often closer than we think.&lt;/p>
&lt;p>So, the question remains: Can you climb the &lt;strong>Deception Ladder&lt;/strong>, or will it collapse beneath you?&lt;/p></description></item></channel></rss>